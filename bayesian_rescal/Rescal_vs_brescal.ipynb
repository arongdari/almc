{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESCAL vs BayesianRESCAL on KINSHIP dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Bayesian RESCAL model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the generative process of triple (entity, relation, entity):\n",
    "\n",
    "For each entity $i$, a latent representation of the entity $e_i \\in \\mathbb{R}^{D}$ is drawn from the zero mean multivariate-normal distribution with diagonal covariance matrix:\n",
    "\n",
    "$$e_i \\sim N(0, \\sigma_e^2 I_D)$$\n",
    "\n",
    "For each relation $k$, relation matrix $R_k \\in \\mathbb{R}^{D\\times D}$ is drawn from the matrix normal distribution with diagonal covariance matrices:\n",
    "\n",
    "$$R_k \\sim MN(0, \\sigma_r^2 I_D, I_D)$$\n",
    "\n",
    "For each triple $(i, k, j)$, the observed value of the triple $x_{i,k,j}$ is drawn from the normal distribution with bilinear mean and variance:\n",
    "\n",
    "$$x_{ikj} \\sim N(e_i^\\top R_k e_j, \\sigma_x^2)$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import logging\n",
    "from scipy.io.matlab import loadmat\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import rescal\n",
    "from brescal import BayesianRescal\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#logger = logging.getLogger()\n",
    "#logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 104, 104)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'kinship'\n",
    "mat = loadmat('../data/%s/alyawarradata.mat' % (dataset))\n",
    "T = np.array(mat['Rs'], np.float32)\n",
    "\n",
    "max_iter = 20\n",
    "\n",
    "n_dim = 10\n",
    "T = np.swapaxes(T, 1, 2)\n",
    "T = np.swapaxes(T, 0, 1)  # [relation, entity, entity]\n",
    "n_relation, n_entity, _ = T.shape\n",
    "print(T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Splitting the kinship dataset into train/test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`trainT` only contains a partial observation of the original tensor `T`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size 1036\n",
      "test size 9754\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "trainT = np.zeros_like(T)\n",
    "p = 0.1\n",
    "\n",
    "train_mask = np.random.binomial(1, p, T.shape)\n",
    "trainT[train_mask==1] = T[train_mask==1]\n",
    "test_mask = np.ones_like(T)\n",
    "test_mask[train_mask==1] = 0\n",
    "print('training size %d' % np.sum(trainT))\n",
    "print('test size %d' % np.sum(T[test_mask==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training BayesianRESCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Grid search on variance parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare performances of different configuration of variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>RESULT(GRID SEARCH)</font>: BayesianRESCAL does not work well when variance of x is equal or larger than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_x:0.010, var_e:1.000, var_r:1.000, AUC-ROC:0.798\n",
      "var_x:0.001, var_e:1.000, var_r:1.000, AUC-ROC:0.872\n",
      "(0.001, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "var_list = [0.01, 0.001]\n",
    "var_e = 1\n",
    "var_r = 1\n",
    "best_roc = 0\n",
    "for var_x in var_list:\n",
    "    model = BayesianRescal(n_dim, var_e=var_e, var_x=var_x, var_r=var_r)\n",
    "    model.fit(trainT, max_iter=max_iter)\n",
    "    _T = model._reconstruct()\n",
    "    score = roc_auc_score(T[test_mask==1], _T[test_mask==1])\n",
    "    print('var_x:{0:3.3f}, var_e:{1:3.3f}, var_r:{2:3.3f}, AUC-ROC:{3:.3f}'.format(var_x, var_e, var_r, score))\n",
    "    if score > best_roc:\n",
    "        best_vars = (var_x, var_e, var_r)\n",
    "        best_model = model\n",
    "        best_roc = score\n",
    "\n",
    "var_x, var_e, var_r = best_vars\n",
    "print(best_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Training RESCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = list()\n",
    "for k in range(n_relation):\n",
    "    X.append(csr_matrix(trainT[k]))\n",
    "    \n",
    "A, R, f, itr, exectimes = rescal.rescal_als(X, n_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Compare both models by ROC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>RESULT</font>: BayesianRESCAL is comparable with RESCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC score of BRESCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871707853872\n"
     ]
    }
   ],
   "source": [
    "_T = best_model._reconstruct()\n",
    "print(roc_auc_score(T[test_mask==1], _T[test_mask==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC score of RESCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87840503508\n"
     ]
    }
   ],
   "source": [
    "_X = np.zeros_like(T)\n",
    "for k in range(T.shape[0]):\n",
    "    _X[k] = np.dot(np.dot(A, R[k]), A.T)\n",
    "print(roc_auc_score(T[test_mask==1], _X[test_mask==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Initialize Bayesian_RESCAL with RESCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see that Bayesian_RESCAL performs worse than RESCAL because it can't escape from local optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A, R, f, itr, exectimes = rescal.rescal_als(X, n_dim)\n",
    "model = BayesianRescal(n_dim, var_e=var_e, var_x=var_x, var_r=var_r)\n",
    "model.n_relations = n_relation\n",
    "model.n_entities = n_entity\n",
    "model.E = A\n",
    "model.R = np.zeros([n_relation, n_dim, n_dim])\n",
    "for k in range(n_relation):\n",
    "    model.R[k] = R[k]\n",
    "model._gibbs(trainT, max_iter=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC-AUC score of BRESCAL initialized by RESCAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852329532385\n"
     ]
    }
   ],
   "source": [
    "_T = model._reconstruct()\n",
    "print(roc_auc_score(T[test_mask==1], _T[test_mask==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Place difference variances on observed / unobserved data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I adopt idea from implicit feedback approach from the following paper in which they place a different variance on observed/unobserved variables (variance of observed variable is smaller than those of unobserved):\n",
    "\n",
    "*Collaborative Filtering for Implicit Feedback Datasets, Yifan Hu, et al. ICDM2008*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>RESULT</font>: BayesianRESCAL with controlled variance (CV_BRESCAL) performs slightly better than BRESCAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.879965167208\n"
     ]
    }
   ],
   "source": [
    "observed_var = 0.001\n",
    "unobserved_var = 1.\n",
    "n_trial = 1\n",
    "for i in range(n_trial):\n",
    "    model = BayesianRescal(n_dim, var_e=var_e, var_x=var_x, var_r=var_r, controlled_var=True, \n",
    "                           obs_var=observed_var, unobs_var=unobserved_var)\n",
    "    model.fit(trainT, max_iter=max_iter)\n",
    "    _T = model._reconstruct()\n",
    "    print(roc_auc_score(T[test_mask==1], _T[test_mask==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.932805011012\n"
     ]
    }
   ],
   "source": [
    "observed_var = 0.01\n",
    "unobserved_var = 1.\n",
    "for i in range(n_trial):\n",
    "    model = BayesianRescal(n_dim, var_e=var_e, var_x=var_x, var_r=var_r, controlled_var=True, \n",
    "                           obs_var=observed_var, unobs_var=unobserved_var)\n",
    "    model.fit(trainT, max_iter=max_iter)\n",
    "    _T = model._reconstruct()\n",
    "    print(roc_auc_score(T[test_mask==1], _T[test_mask==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.755790573864\n"
     ]
    }
   ],
   "source": [
    "observed_var = 0.001\n",
    "unobserved_var = 10.\n",
    "for i in range(n_trial):\n",
    "    model = BayesianRescal(n_dim, var_e=var_e, var_x=var_x, var_r=var_r, controlled_var=True, \n",
    "                           obs_var=observed_var, unobs_var=unobserved_var)\n",
    "    model.fit(trainT, max_iter=max_iter)\n",
    "    _T = model._reconstruct()\n",
    "    print(roc_auc_score(T[test_mask==1], _T[test_mask==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549421288247\n"
     ]
    }
   ],
   "source": [
    "observed_var = 0.001\n",
    "unobserved_var = 100.\n",
    "for i in range(n_trial):\n",
    "    model = BayesianRescal(n_dim, var_e=var_e, var_x=var_x, var_r=var_r, controlled_var=True, \n",
    "                           obs_var=observed_var, unobs_var=unobserved_var)\n",
    "    model.fit(trainT, max_iter=max_iter)\n",
    "    _T = model._reconstruct()\n",
    "    print(roc_auc_score(T[test_mask==1], _T[test_mask==1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Parameter optimization for RESCAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESCAL also has some parameters to be tuned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='red'>RESULT</font>: RESCAL is highly robust w.r.t the parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "var_x:0.001, var_e:0.001, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.001, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.001, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.001, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.001, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.001, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.010, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.010, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.010, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.010, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.010, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.010, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.100, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.100, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.100, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.100, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.100, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:0.100, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:1.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:1.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:1.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:1.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:1.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:1.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:10.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:10.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:10.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:10.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:10.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:10.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:100.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:100.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:100.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:100.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:100.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.001, var_e:100.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.001, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.001, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.001, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.001, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.001, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.001, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.010, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.010, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.010, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.010, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.010, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.010, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.100, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.100, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.100, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.100, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.100, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:0.100, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:1.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:1.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:1.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:1.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:1.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:1.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:10.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:10.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:10.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:10.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:10.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:10.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:100.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:100.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:100.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:100.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:100.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.010, var_e:100.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.001, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.001, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.001, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.001, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.001, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.001, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.010, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.010, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.010, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.010, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.010, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.010, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.100, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.100, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.100, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.100, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.100, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:0.100, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:1.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:1.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:1.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:1.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:1.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:1.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:10.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:10.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:10.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:10.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:10.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:10.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:0.100, var_e:100.000, var_r:0.001, AUC-ROC:0.931\n",
      "var_x:0.100, var_e:100.000, var_r:0.010, AUC-ROC:0.931\n",
      "var_x:0.100, var_e:100.000, var_r:0.100, AUC-ROC:0.931\n",
      "var_x:0.100, var_e:100.000, var_r:1.000, AUC-ROC:0.931\n",
      "var_x:0.100, var_e:100.000, var_r:10.000, AUC-ROC:0.931\n",
      "var_x:0.100, var_e:100.000, var_r:100.000, AUC-ROC:0.931\n",
      "var_x:1.000, var_e:0.001, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.001, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.001, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.001, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.001, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.001, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.010, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.010, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.010, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.010, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.010, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.010, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.100, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.100, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.100, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.100, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.100, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:0.100, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:1.000, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:1.000, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:1.000, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:1.000, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:1.000, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:1.000, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:1.000, var_e:10.000, var_r:0.001, AUC-ROC:0.929\n",
      "var_x:1.000, var_e:10.000, var_r:0.010, AUC-ROC:0.929\n",
      "var_x:1.000, var_e:10.000, var_r:0.100, AUC-ROC:0.929\n",
      "var_x:1.000, var_e:10.000, var_r:1.000, AUC-ROC:0.929\n",
      "var_x:1.000, var_e:10.000, var_r:10.000, AUC-ROC:0.929\n",
      "var_x:1.000, var_e:10.000, var_r:100.000, AUC-ROC:0.929\n",
      "var_x:1.000, var_e:100.000, var_r:0.001, AUC-ROC:0.931\n",
      "var_x:1.000, var_e:100.000, var_r:0.010, AUC-ROC:0.931\n",
      "var_x:1.000, var_e:100.000, var_r:0.100, AUC-ROC:0.931\n",
      "var_x:1.000, var_e:100.000, var_r:1.000, AUC-ROC:0.931\n",
      "var_x:1.000, var_e:100.000, var_r:10.000, AUC-ROC:0.931\n",
      "var_x:1.000, var_e:100.000, var_r:100.000, AUC-ROC:0.931\n",
      "var_x:10.000, var_e:0.001, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.001, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.001, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.001, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.001, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.001, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.010, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.010, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.010, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.010, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.010, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.010, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.100, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.100, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.100, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.100, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.100, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:0.100, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:10.000, var_e:1.000, var_r:0.001, AUC-ROC:0.930\n",
      "var_x:10.000, var_e:1.000, var_r:0.010, AUC-ROC:0.930\n",
      "var_x:10.000, var_e:1.000, var_r:0.100, AUC-ROC:0.930\n",
      "var_x:10.000, var_e:1.000, var_r:1.000, AUC-ROC:0.930\n",
      "var_x:10.000, var_e:1.000, var_r:10.000, AUC-ROC:0.930\n",
      "var_x:10.000, var_e:1.000, var_r:100.000, AUC-ROC:0.930\n",
      "var_x:10.000, var_e:10.000, var_r:0.001, AUC-ROC:0.931\n",
      "var_x:10.000, var_e:10.000, var_r:0.010, AUC-ROC:0.931\n",
      "var_x:10.000, var_e:10.000, var_r:0.100, AUC-ROC:0.931\n",
      "var_x:10.000, var_e:10.000, var_r:1.000, AUC-ROC:0.931\n",
      "var_x:10.000, var_e:10.000, var_r:10.000, AUC-ROC:0.931\n",
      "var_x:10.000, var_e:10.000, var_r:100.000, AUC-ROC:0.931\n",
      "var_x:10.000, var_e:100.000, var_r:0.001, AUC-ROC:0.500\n",
      "var_x:10.000, var_e:100.000, var_r:0.010, AUC-ROC:0.500\n",
      "var_x:10.000, var_e:100.000, var_r:0.100, AUC-ROC:0.500\n",
      "var_x:10.000, var_e:100.000, var_r:1.000, AUC-ROC:0.500\n",
      "var_x:10.000, var_e:100.000, var_r:10.000, AUC-ROC:0.500\n",
      "var_x:10.000, var_e:100.000, var_r:100.000, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:0.001, var_r:0.001, AUC-ROC:0.944\n",
      "var_x:100.000, var_e:0.001, var_r:0.010, AUC-ROC:0.944\n",
      "var_x:100.000, var_e:0.001, var_r:0.100, AUC-ROC:0.944\n",
      "var_x:100.000, var_e:0.001, var_r:1.000, AUC-ROC:0.944\n",
      "var_x:100.000, var_e:0.001, var_r:10.000, AUC-ROC:0.944\n",
      "var_x:100.000, var_e:0.001, var_r:100.000, AUC-ROC:0.944\n",
      "var_x:100.000, var_e:0.010, var_r:0.001, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.010, var_r:0.010, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.010, var_r:0.100, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.010, var_r:1.000, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.010, var_r:10.000, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.010, var_r:100.000, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.100, var_r:0.001, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.100, var_r:0.010, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.100, var_r:0.100, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.100, var_r:1.000, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.100, var_r:10.000, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:0.100, var_r:100.000, AUC-ROC:0.931\n",
      "var_x:100.000, var_e:1.000, var_r:0.001, AUC-ROC:0.707\n",
      "var_x:100.000, var_e:1.000, var_r:0.010, AUC-ROC:0.707\n",
      "var_x:100.000, var_e:1.000, var_r:0.100, AUC-ROC:0.707\n",
      "var_x:100.000, var_e:1.000, var_r:1.000, AUC-ROC:0.707\n",
      "var_x:100.000, var_e:1.000, var_r:10.000, AUC-ROC:0.707\n",
      "var_x:100.000, var_e:1.000, var_r:100.000, AUC-ROC:0.707\n",
      "var_x:100.000, var_e:10.000, var_r:0.001, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:10.000, var_r:0.010, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:10.000, var_r:0.100, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:10.000, var_r:1.000, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:10.000, var_r:10.000, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:10.000, var_r:100.000, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:100.000, var_r:0.001, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:100.000, var_r:0.010, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:100.000, var_r:0.100, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:100.000, var_r:1.000, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:100.000, var_r:10.000, AUC-ROC:0.500\n",
      "var_x:100.000, var_e:100.000, var_r:100.000, AUC-ROC:0.500\n",
      "(10.0, 0.1, 0.001) 0.943742194506\n"
     ]
    }
   ],
   "source": [
    "var_list = [0.001, 0.01, 0.1, 1., 10., 100.]\n",
    "best_roc = 0\n",
    "for (var_x, var_e, var_r) in itertools.product(var_list,repeat=3):\n",
    "    A, R, f, itr, exectimes = rescal.rescal_als(X, n_dim, lambda_A=var_x, lambda_R=var_e, lambda_V=var_r)\n",
    "    _X = np.zeros_like(T)\n",
    "    for k in range(T.shape[0]):\n",
    "        _X[k] = np.dot(np.dot(A, R[k]), A.T)\n",
    "    score = roc_auc_score(T.flatten(), _X.flatten())\n",
    "    print('var_x:{0:3.3f}, var_e:{1:3.3f}, var_r:{2:3.3f}, AUC-ROC:{3:.3f}'.format(var_x, var_e, var_r, score))\n",
    "    if score > best_roc:\n",
    "        best_vars = (var_x, var_e, var_r)\n",
    "        best_model = model\n",
    "        best_roc = score\n",
    "        \n",
    "lambda_a, lambda_r, lambda_v = best_vars\n",
    "print(best_vars, best_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## For paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "from scipy.sparse import csr_matrix\n",
    "import logging\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "import rescal\n",
    "from brescal import BayesianRescal\n",
    "from runner import load_dataset\n",
    "from seq_brescal import PFBayesianRescal\n",
    "from seq_logit_brescal import PFBayesianLogitRescal\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logger = logging.getLogger()\n",
    "for handler in logger.handlers:\n",
    "    logger.removeHandler(handler)\n",
    "\n",
    "\n",
    "datasets = ['kinship', 'umls', 'nation']\n",
    "\n",
    "result = dict()\n",
    "train_test_validation = dict()\n",
    "n_trial = 10\n",
    "max_iter = 20\n",
    "n_dim = 10\n",
    "\n",
    "models = ['rescal', 'brescal', 'blogit']\n",
    "for dataset in datasets:\n",
    "    train_test_validation[(dataset)] = list()\n",
    "    \n",
    "for model, dataset in itertools.product(models, datasets):\n",
    "    result[(dataset, model)] = list()\n",
    "\n",
    "if not os.path.exists('../result/rescal_vs_brescal.pkl'):\n",
    "    for nt in range(n_trial):\n",
    "        tic = time.time()\n",
    "\n",
    "        for dataset in datasets:\n",
    "            T = load_dataset(dataset)\n",
    "            n_relation, n_entity, _ = T.shape\n",
    "\n",
    "            samples = [(i, j, k) for i, j, k in itertools.product(range(n_relation), range(n_entity), range(n_entity))]\n",
    "            total = np.prod(T.shape)\n",
    "            np.random.shuffle(samples)\n",
    "            train_p = 0.1\n",
    "            validation_p = 0.3\n",
    "            test_p = 1. - validation_p - train_p\n",
    "            train_test_validation[dataset].append(samples)\n",
    "\n",
    "            train_mask = np.zeros_like(T)\n",
    "            validation_mask = np.zeros_like(T)\n",
    "            test_mask = np.zeros_like(T)\n",
    "            for idx in range(int(total * train_p)):\n",
    "                i, j, k = samples[idx]\n",
    "                train_mask[i, j, k] = 1\n",
    "            for idx in range(int(total * validation_p)):\n",
    "                i, j, k = samples[int(total * train_p) + idx]\n",
    "                validation_mask[i, j, k] = 1\n",
    "            for idx in range(int(total * test_p)):\n",
    "                i, j, k = samples[int(total * train_p) + int(total * validation_p) + idx]\n",
    "                test_mask[i, j, k] = 1\n",
    "\n",
    "            trainT = np.zeros_like(T)\n",
    "            trainT[train_mask == 1] = T[train_mask == 1]\n",
    "\n",
    "\n",
    "            lambda_As = [0.01, 0.1, 1.]\n",
    "            lambda_Rs = [0.01, 0.1, 1.]\n",
    "            best_roc = 0\n",
    "            for lambda_A, lambda_R in itertools.product(lambda_As, lambda_Rs):\n",
    "                X = list()\n",
    "                for k in range(n_relation):\n",
    "                    X.append(csr_matrix(trainT[k]))\n",
    "                A, R, f, itr, exectimes = rescal.rescal_als(X, n_dim, lambda_A=lambda_A, lambda_R=lambda_R)\n",
    "                _X = np.zeros_like(T)\n",
    "                for k in range(T.shape[0]):\n",
    "                    _X[k] = np.dot(np.dot(A, R[k]), A.T)\n",
    "                score = roc_auc_score(T[validation_mask == 1], _X[validation_mask == 1])\n",
    "                if score > best_roc:\n",
    "                    best_vars = (lambda_A, lambda_R)\n",
    "                    best_A, best_R = A, R\n",
    "                    best_roc = score\n",
    "\n",
    "            _X = np.zeros_like(T)\n",
    "            for k in range(T.shape[0]):\n",
    "                _X[k] = np.dot(np.dot(best_A, best_R[k]), best_A.T)\n",
    "            score = roc_auc_score(T[test_mask == 1], _X[test_mask == 1])\n",
    "            print('RESCAL', dataset, best_vars, score)\n",
    "            result[(dataset, models[0])].append(score)\n",
    "            \n",
    "            \n",
    "            var_list = [0.001, 0.01, 0.1]\n",
    "            var_e = 1\n",
    "            var_r = 1\n",
    "            best_roc = 0\n",
    "            for var_x in var_list:\n",
    "                _model = PFBayesianRescal(n_dim, var_x=var_x, n_particles=1, compute_score=False,\n",
    "                                          parallel=False, sample_all=True)\n",
    "                seq = _model.fit(T, obs_mask=train_mask.copy(), max_iter=0)\n",
    "                _T = _model._reconstruct(_model.E[0], _model.R[0])\n",
    "                score = roc_auc_score(T[validation_mask == 1], _T[validation_mask == 1])\n",
    "                if score > best_roc:\n",
    "                    best_vars = (var_x, var_e, var_r)\n",
    "                    best_model = _model\n",
    "                    best_roc = score\n",
    "\n",
    "            _T = best_model._reconstruct(best_model.E[0], best_model.R[0])\n",
    "            score = roc_auc_score(T[test_mask == 1], _T[test_mask == 1])\n",
    "            print('BRESCAL', dataset, best_vars, score)\n",
    "            result[(dataset, models[1])].append(score)\n",
    "\n",
    "\n",
    "    #         observed_vars = [0.01, 0.001]\n",
    "    #         unobserved_vars = [1., 10.]\n",
    "    #         best_roc = 0\n",
    "    #         for observed_var, unobserved_var in itertools.product(observed_vars, unobserved_vars):\n",
    "    #             model = BayesianRescal(n_dim, var_e=var_e, var_r=var_r, controlled_var=True,\n",
    "    #                                    obs_var=observed_var, unobs_var=unobserved_var)\n",
    "    #             model.fit(trainT, max_iter=max_iter)\n",
    "    #             _T = model._reconstruct()\n",
    "    #             score = roc_auc_score(T[validation_mask == 1], _T[validation_mask == 1])\n",
    "    #             if score > best_roc:\n",
    "    #                 best_vars = (observed_var, unobserved_var)\n",
    "    #                 best_model = model\n",
    "    #                 best_roc = score\n",
    "\n",
    "    #         _T = best_model._reconstruct()\n",
    "    #         score = roc_auc_score(T[test_mask == 1], _T[test_mask == 1])\n",
    "    #         print('BRESCAL_CTRL', dataset, score)\n",
    "    #         result[(dataset,'brescal_ctrl')].append(score)\n",
    "\n",
    "\n",
    "            _model = PFBayesianLogitRescal(n_dim, n_particles=1, compute_score=False)\n",
    "            seq = _model.fit(T, obs_mask=train_mask.copy(), max_iter=0)\n",
    "            particle = _model.p_weights.argmax()\n",
    "            _T = _model._reconstruct(_model.E[0], _model.R[0])\n",
    "            score = roc_auc_score(T[test_mask == 1], _T[test_mask == 1])\n",
    "            print('BRESCAL_LOGIT', dataset, score)\n",
    "            result[(dataset, models[2])].append(score)\n",
    "\n",
    "        print(time.time() - tic)\n",
    "\n",
    "    pickle.dump([result, train_test_validation], open('../result/rescal_vs_brescal.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAADPCAYAAAAOAlMXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndbH/B2rH8yfDi0vkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c56a8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result, samples = pickle.load(open('../result/rescal_vs_brescal.pkl', 'rb'))\n",
    "\n",
    "plt.figure(figsize=(8, 2.4))\n",
    "width = 1\n",
    "title_size = 14\n",
    "label_size = 12\n",
    "\n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]    \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)    \n",
    "\n",
    "for plt_no, dataset in enumerate(datasets):\n",
    "    plt.subplot(1, len(datasets), plt_no+1)\n",
    "\n",
    "    for model in models:\n",
    "        mean = np.mean(result[(dataset,model)])\n",
    "        std = np.std(result[(dataset,model)])\n",
    "        label = model.upper()\n",
    "        if model == 'brescal_logit':\n",
    "            label = 'BLOGIT'\n",
    "        plt.bar(models.index(model)+0.15, mean, width-0.3, color=tableau20[models.index(model)], yerr=std, label=label)\n",
    "    plt.xticks(np.arange(len(models))+0.50, ['%s'% (model.upper()) for model in models], rotation=45)\n",
    "\n",
    "    if plt_no == 0:\n",
    "#        plt.legend(loc='lower left')        \n",
    "#        plt.setp(plt.gca().get_legend().get_texts(), fontsize='10')\n",
    "        plt.ylabel('ROC-AUC score', size=label_size)\n",
    "\n",
    "\n",
    "#     plt.tick_params(\n",
    "#         axis='x',          # changes apply to the x-axis\n",
    "#         which='both',      # both major and minor ticks are affected\n",
    "#         bottom='off',      # ticks along the bottom edge are off\n",
    "#         top='off',         # ticks along the top edge are off\n",
    "#         labelbottom='off') # labels along the bottom edge are off\n",
    "\n",
    "    plt.title('%s' % dataset.upper(), size=title_size)\n",
    "    plt.ylim((0.4,1))\n",
    "\n",
    "# plt.savefig('../paper/images/rescal_vs_brescal.pdf', format='PDF', bbox_inches='tight', pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
