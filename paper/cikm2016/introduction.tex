%!TEX root = ./cikm2016.tex

\section{Introduction}
\label{sec:intro}

Relational knowledge bases structuralise our understanding about the world into the form of \textit{(entity1, relation, entity2)} triples
that help reasoning and inferring in a wide range of tasks such as information retrieval, question answering, and semantic parsing~\cite{Dong2015,jiang2015improving,kim2013context,sondhi2014mining}.
A construction of a knowledge base is a very active research area with many important and challenging research questions.
The early stage of knowledge base construction relies on {\bf knowledge population} task
in which structured information from external sources are extracted, 
or human experts encode a prior knowledge manually.
Despite the endeavour toward to construct a complete knowledge base, 
even the commercialised knowledge bases are still far from complete~\cite{dong2014knowledge}. 
{\bf Knowledge completion} task has been emerged as an complement of the knowledge population 
to scale up the knowledge base construction. Unlike the knowledge population task where the goal is to maximise the number of triples, the goal of knowledge completion is to maximise the predictive performance on unseen triples through a statistical analysis on the extracted information \cite{guu2015traversing,Lao2010}.
%There are two main knowledge completion approaches. First, latent feature models factorise entities and relations to predict unseen triples. Second, graph feature models 

One major obstacle of knowledge base construction is a gap between knowledge 
population and completion. For example, when there is no external source to extract knowledge,
the construction relies solely on the contribution of human experts.
Manual labelling is often painful and tedious, 
therefore triples that will be labelled should be selected in an active way so 
that we can maximise the performance of following knowledge completion.
Active learning may provide a systematic way of selecting a data point to be labelled with one of knowledge completion models~\cite{Settles2010}. However, it is not clear that which model from the knowledge completion should be used for the active selection because of the discrepancy between two different goals of knowledge population and completion.
%However, the selection of proper model is still ambiguous and arbitrary for the active acquisition task. 
%In the active learning literature, it is often ignored that which model for a predictive task is appropriate for its active counterpart. 

We provide a model based active query selection approach to see how the models from the latter task can be used for the former task. We first reformulate a bilinear tensor factorisation~\cite{nickel2015review} in a probabilistic way, where entities and relations are embedded into latent feature space. And then we propose a novel tensor factorisation model that incorporates the graph structure of knowledge base into the factorisation model. These two probabilistic models provide a natural way of embracing uncertainty of triples that is crucial to develop 
an active triple selection for the active knowledge population.
With Thompson sampling~\cite{scott10bandit} -- an approach for solving the multi-armed bandit problem,
the model find an optimal trade-off between exploration and exploitation when identifying new triples.

Based on experiments with three real-world datasets, we find that the models outperformed in the knowledge completion may not perform well in the active knowledge population. Because, for the knowledge completion, it is important to find a better latent structure given current observation, for the active population, however, it is more important to  measure the uncertainty of a current model in order to explore the latent space efficiently over time.
As far as we know, this is the first study that explicitly reveals how the knowledge completion models result in different conclusions in the active knowledge population.

The contributions of this paper can be summarised as follows:
\begin{itemize}
\item We propose a probabilistic reformulation of bilinear tensor factorisation that allows us to predict and measure the uncertainty of unobserved triples in Section \ref{sec:brescal}.
\item We incorporate a compositional structure of knowledge graph into the proposed factorisation by modelling a composition of relations as an algebraic operation in the probabilistic embedding space in Section \ref{sec:comp}.
\item We propose an active knowledge population method that efficiently explore the factorised space guided by a principled way of exploration-exploitation via Thompson sampling algorithm in Section \ref{sec:pts}.
\item Experiments on the knowledge completion with three real-world dataset show that the compositional model predicts unseen triples better than the bilinear factorisation model in Section \ref{sec:exp1}.
\item Experiments show the importance of uncertainty in the active population. Especially, the better predictive model does not guarantee to have a better knowledge population due to an improper uncertainty measure in Section \ref{sec:exp2}.
\end{itemize}

\eat{
%KG background from text, completion
Relational knowledge bases support reasoning, information retrieval, 
or question-answering tasks about entities and their relations.
Most of them contain facts in the form of (entity1, relation, entity2) triples, 
such as (CarlFriedrichGauss, BornIn, Braunschweig).
%(ThomasBayes, London, BornIn).
Automatically acquiring, maintaining, and reasoning in
knowledge bases is a very active topic area with many important and challenging research questions. 
%, has sustained attention from both academia and industry. 
Even the largest of such databases are known to be incomplete~\cite{dong2014knowledge}. %min2013distant
There are two main ways to fill in the missing facts:
the first learning new relations from large collections of text or hyper-text,
%~\cite{Mintz2009,carlson2010toward}, 
known as knowledge extraction, 
the second is inferring facts from existing relations, %~\cite{Lao2010,nickel2015review} 
known as knowledge completion. 

%There are two open 
One challenge in knowledge base completion is 
its disconnection from the knowledge extraction setting. 
It would be nice, for example, to know which question to query for in 
a search-based method for gathering triples~\cite{west2014knowledge}. 
Recently \cite{kajino2015active} propose an active learning strategy for completing 
knowledge triples; however the algorithm had problems simultaneously achieving high recall and faithful reconstruction.
% finds it difficult to achieve 
%high recall and high reconstruction at the same time. 
Having an active exploit-explore strategy would more effectively 
connect knowledge completion and extraction problems. 
Another challenge is leveraging compositional knowledge from existing triples. 
Also known as paths in knowledge graphs, composition of facts is key to 
achieving common reasoning tasks. 
For example, the two triples (CarlFriedrichGauss, BornIn, Braunschweig)
and (Braunschweig, LocatedIn, Germany) implies (CarlFriedrichGauss, BornIn Germany). 
Path ranking~\cite{Lao2010}, vector space traversal~\cite{guu2015traversing}
and composition~\cite{Neelakantan2015} techniques 
are recently developed to leverage such information for knowledge completion. 
We note, however, that a principled formulation that can address 
both open challenges is still missing -- namely, a relational model 
that can model knowledge compositions in an active setting. 

%\TODO{TODO}{revise summary-of-our-approach to be consistent w. the above}
We propose a novel probabilistic reformulation of tensor factorisation,  
one of the main competitive variants for knowledge completion~\cite{nickel2015review}. 
%There are many advantages to a probabilistic formulation of tensor factorisation, 
%such as the quantification of uncertainty by the predictive distribution, 
%the ability to utilise priors, and the availability of principled model selection. 
We name our model probabilistic RESCAL (PRESCAL).
The probabilistic model provides a natural way of 
embracing uncertainty of triples that is crucial to develop 
%implementing
an active triple selection for knowledge completion, using  
Thompson sampling~\cite{scott10bandit} -- an approach for solving the multi-armed bandit problem,
which allows us to trade-off exploration and exploitation when identifying new triples.
%randomized probability matching, also known as Thompson sampling~\cite{scott10bandit}.
We also perform compositional training for the probabilistic model, 
by modeling relation compositions as algebraic operations in the probabilistic embedding space. 
For inference, we design Gibbs sampling for PRESCAL with and without compositions. 
%with by computing conditional posteriors. 
We employ a sequential Monte-Carlo method for the active querying of new triples, 
called particle Thompson sampling. 

We first test the proposed models with synthetic datasets. 
We observe that Thompson sampling provides significant gain over random sampling of triples; 
we also observe a clear gain in tensors with known composition structure. 
We then evaluated the model on three real-world relation datasets. In the passive learning setting, 
we find PRESCAL outperforming the non-probabilistic version of tensor factorisation, 
and that compositions help when the training set is sparse. 
In the active learning scenario, 
we find that PRESCAL achieves the highest cumulative gain across all datasets. 
It is encouraging to see the exploitation-exploration strategy with uncertainty outperforming 
active learning strategies that focus solely on exploitation or exploration. 

We are pleased to be able to learn a vector-space model for entities and relations with uncertainty, 
bridging the gap of probabilistic active sampling and knowledge compositions. 
We look forward to follow-on work with better sampling strategies and computational scalability. 
}

\eat{
Statistical relational models have been proposed to tackle
various problems of knowledge bases. For example, it can be used 
for question understanding and answering problems ,
or it can be integrated into a search engine
to improve the users' search experiment \cite{dong2014knowledge}.

However, most of previous latent feature models lack the consideration
of constructing a knowledge graph with the latent features.
As an alternative approach, distant supervision algorithms
\cite{Mintz2009} suggest a way to fill a missing part of knowledge graph
through the extensive NLP processing, however, this method inherently
requires a set of initial observations used as a distant supervision.

Here, we tackle the problem of knowledge base construction with the
statistical relational model.
A goal of knowledge base construction is to acquire a maximum number
of valid triples with a limited budget.
This goal corresponds to a general objective of the multi-armed bandit (MAP)
problem where we want to minimise the cumulative regret or maximise
the cumulative reward over time. 
In recent years, Thompson sampling has been emerged as  
an competitive solution in MAP problems.
We borrow Thompson sampling, which provides a principled
way to find an optimal trade off between exploration and exploitation,
to solve the knowledge base construction problem.
}

\eat{
We propose a compositional relation model that exploit the compositional structure of 
knowledge graph to capture the latent semantic structure of the entities and relations.
While previously suggested vector space models provide a statistical way to infer the latent semantic 
structure of entities and relations, but lack consideration of a graph structure of a knowledge base itself.

In a separate way from the vector space models, graph feature algorithms such as the path ranking algorithm 
are suggested to fill a missing part of a knowledge graph \cite{Lao2010}. The graph feature algorithms 
directly include graph structures, such as edge type, node type, and node degree, to learn and predict new 
triples, however, the absence of latent structure makes the models failed to predict a new triple when the 
target entities does not have rich structural background\cite{nickel2015review}.

We propose a compositional vector space model that benefits the latent representation of vector space model 
along with the graph structure of the graph feature models. Recently, Guu et. al. suggest a compositional 
training framework for vector space models \cite{gu2015traversing}, where paths over a knowledge graph act 
as a new form of structural regularisation of the models. Based on their work, we extend the compositional 
approach within a probabilistic framework with two compositional structures.
}

\eat{%% v1 of intro
As the amount of information codified in a computer readable fashion increases, the management
of knowledge bases need to become increasingly more automated. In this paper, we study
the problem of acquiring new knowledge given an existing knowledge base. Knowledge bases
are modelled as a set of relations between pairs of entities, for example the factoid
``Barack Obama is the 44th president of the United States''
is modelled as two entities (Barack Obama, United States) being related by ``president of''.
Such relations have a natural representation as a sparse graph or a tensor of order 3.
Given this representation, we model the acquisition of new knowledge as the
identification of new triples that capture particular relations between two entities.

There are several challenges when we apply machine learning methods to completing
existing knowledge bases, namely:
sparse, noisy, and incomplete annotations.
There has been recent success in transferring ideas from matrix completion problems to
the tensor domain to overcome the challenge of sparsity~\cite{unknown}.
We follow this thread of research by using a low rank approximation model for tensor
factorisation. Such low rank approximations can also be seen as a latent variable probabilistic
model, which additionally captures the inherent uncertainty of noisy annotations.
We propose a probabilistic model for tensor factorisation and explore both the Gaussian
and Logistic model. The probabilistic model provides a natural way of implementing
randomised probability matching, also known as Thompson sampling~\cite{scott10bandit}.
Thompson sampling is an approach for solving the multi-armed bandit problem,
which allows us to trade off exploration and exploitation when identifying new triples.
This provides a principled approach to identify promising candidates for knowledge base
completion.
We additionally consider compositional relations as an additional source of weak information
to further utilise the existing (incomplete) knowledge items.

Goal of this paper 1: Populating knowledge graph with an active label acquisition process 
corresponding to [B,C,A] in Figure \ref{fig:related3d}.

[B,C,P] could be an alternative direction (or both).
}
