%!TEX root = ./cikm2016.tex
% \section{Discussion and Conclusion}
\section{Conclusion}
Throughout the paper, we have considered the two knowledge base construction tasks: knowledge population and knowledge completion.
Based on a probabilistic framework, we propose new knowledge base factorisation methods where the latent factorisation reflects a graph structure of a knowledge graph. The probabilistic formulation allows us to quantify the uncertainty of predictive distributions, which is then used for the knowledge population task. The experiments of two tasks on three dataset show that the compositional model benefits graph structure for the knowledge completion, and the probabilistic formulation helps to explore the latent space efficiently for the knowledge population.

\eat{
We consider two tasks when constructing knowledge graphs:
populating it from external sources,
and completing it using known knowledge items~\cite{dong2014knowledge}.
In contrast to previous work~\cite{kajino2015active}, that
views knowledge population and knowledge completion as separate problems,
we propose an approach that enables a common modelling and computation solution
for both tasks.
\eat{
We find this observation true when the algorithm has a warm-start,
i.e. already having a fair amount of data before active learning starts;
when the information is sparse, the same strategy works for both maximising
recall and reducing uncertainty.
}
We propose a novel compositional relational model with uncertainty and
demonstrate that it improves over the non-probabilistic and non-compositional
model~\cite{nickel2011three}.
The compositional model infers the latent features of knowledge
bases by incorporating an additional graph structure~\cite{guu2015traversing}.
We investigate the paths arising from the compositional
models and show that it can capture previously unavailable knowledge. A visualisation
of the entity embeddings show a correlation with the types provided in the meta-data.
Using the same model, we investigate the incremental knowledge population task, and propose
a Thompson sampling method for both compositional and non-compositional models.
In the passive learning scenario, the compositional model outperforms the other models,
especially, when training size is relatively small.
In the active learning scenario, probabilistic \textsc{Rescal} achieves the highest
cumulative gain across all datasets. This result emphasises the
importance of balancing exploration and exploitation.

Thompson sampling has been studied in the context of multi-armed bandit
problems where the goal is to maximise cumulative gains or minimise cumulative
regrets over time, whereas its performance on making a predictive model has not
been widely discussed so far. Its performance on building a generalisable model
was unclear. Throughout this work, we have empirically shown that maximising
cumulative gain entails good predictive models as well.
In the long run, we see this work as a promising step towards using a composition-aware knowledge
completion system to connect with the
knowledge based construction problem. %, with rich graph structures.
}
