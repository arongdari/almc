%!TEX root = ./icml2016.tex
\section{Experiments}

\subsection{Synthetic data}
\begin{figure}[t]
	\centering
	
	\subfigure[E=5, K=5, D=5\label{fig:syn1}]{
	\includegraphics[width=0.42\linewidth]{images/toy_5_5_5.pdf}
	}
	\subfigure[E=10, K=10, D=5\label{fig:syn2}]{
	\includegraphics[width=0.45\linewidth]{images/toy_10_10_5.pdf}				
	}
%	\includegraphics[width=0.32\linewidth]{images/toy_5_10_5.pdf}			
%	\includegraphics[width=0.32\linewidth]{images/toy_10_5_5.pdf}				
	\caption{\label{fig:synthetic} Cumulative regret of particle Thompson sampling on different sizes of the 
synthetic dataset. E, K, and D denote the number of entities, relations, and latent dimensions, respectively. 
The synthetic dataset is generated by the model assumption. We compared the particle Thompson sampling 
with passive sampling method. The averaged cumulative regrets are plotted with one standard error. As the 
model obtained more and more labeled samples from Thompson sampling, the cumulative regrets are 
converged. }
\end{figure}

To verify the particle Thompson sampling, we first synthesize data based on the model assumptions and run 
the Thompson sampling algorithm. By following the model assumptions in Eq. \ref{eqn:entity_gen} to 
\ref{eqn:triple_gen}, we randomly generate triples based on randomly sampled entities and relations. Every 
entities and relations are generated from zero-mean isotropic multivariate normal distribution, where we set 
the variance parameters $\sigma_e$, $\sigma_r$, and $\sigma_x$ to 10, 10, and 0.1, respectively.

To measure the performance on synthetic dataset, we compute the cumulative regret of proposed algorithm at 
each time $n$ as follows:
\begin{align}
R(n) = \sum_{t=1}^{n} x_t - x^{*}_t,
\end{align}
where $x^*_t$ is the highest triple among triples that have not been chosen up to time $t$. Unlike the general 
Bandit setting where one can select a single item multiple times, in our formulation, we can select one triple 
only once. So after selecting a triple at time $t$, the selected triple will be removed from a set of candidate 
triples.

Figure \ref{fig:synthetic} shows the cumulative regret of the algorithm on the synthetic data with varying size of 
entities and relations. We compare the cumulative regret of the particle Thompson sampling with the passive 
learning method where the model choose a random triple at each time. All results are averaged over 10 
individual runs with different initializations. For every experiment, the cumulative regret of the Thompson 
sampling method was bounded after a certain number of interactions whereas the cumulative regret of 
passive learning increases linearly. This result indicates the particle sampling correctly inferred latent features 
of entities and relations as the interaction increases.

\subsection{Thompson sampling on real datasets}
\begin{table}[t]
\centering
\caption{\label{tbl:dataset}Description of datasets. Sparsity denotes the ration of valid triples to all possible 
number of triples.}
\begin{tabular}{l | r | r | r | r}
Dataset &  \# rel & \# entities & \# triples & sparsity \\ \hline
Kinship & 26 & 104  & 10,790 & 0.038 \\
UMLS & 49 &135  & 6,752 & 0.008 \\
Nation & 56 & 14  & 2,024 & 0.184 \\
%Wordnet & 11 & 38,696  &123,429 & 7.5e-06\\
%Wordnet(N) & 10 & 836 & 1,766 & 2.5e-04\\
\end{tabular}
\end{table}

\begin{figure}[t]
	\centering
	
	\subfigure[KINSHIP]{
	\includegraphics[width=\linewidth]{images/thompson_kinship.pdf}
	}
	\subfigure[UMLS]{
	\includegraphics[width=\linewidth]{images/thompson_umls.pdf}				
	}
	\subfigure[NATION]{
	\includegraphics[width=\linewidth]{images/thompson_nation.pdf}				
	}	
	\caption{The cumulative gain and ROC-AUC score of the Thompson sampling with various baseline 
approaches. AMDC model uses two different querying strategies }
\end{figure}

Next, we evaluate our algorithms on real datasets and compare the performance to the various baseline 
algorithms. We use three relational datasets: KINSHIP, UMLS, and NATION. Detailed description of each 
dataset is shown in Table \ref{tbl:dataset}.

\textbf{Experimental settings}: For the particle Thompson sampling 

AMDC model uses two different querying strategies to chose a triple to be queried at time $t$. AMDC-POP is 
a population strategy and chose a triple which has the highest expected value at time each $t$. AMDC-PRED 
is a predictive model construction strategy and chose a triple which is the most ambiguous triples (close to the 
decision boundary) at each time $t$ \cite{kajino2015active}.

\textbf{Evaluation metric}: We use two different evaluation metrics, ROC-AUC score, and cumulative gain, for 
the performance comparison. 

\subsection{Compositional Structure}
\begin{figure}[t]
	\centering
	\includegraphics[width=\linewidth]{images/comp_training_error_kinship_small.pdf}
	\includegraphics[width=\linewidth]{images/comp_training_error_umls_small.pdf}			
	\includegraphics[width=\linewidth]{images/comp_training_error_nation_small.pdf}				
	\caption{\label{fig:r_vs_br} ROC-AUC scores of compositional models. The x-axis denotes the proportion 
of an observed triples including negative triples used for training models. We use other 20\% of triples as a 
validation set and another 30\% of triples as a test set. 
%waiting result now...
%In general, compositional models outperform BRESCAL and BLOGIT model when the size of training set is 
%relatively small, whereas BRESCAL and BLOGIT perform slightly better than or comparable to the 
%compositional models when the size of training set is relatively large. For UMLS dataset, the multiplicative 
%compositional model consistently outperforms the other models across all training proportions.
}
\end{figure} 

