%!TEX root = ./icml2016.tex
\section{Particle Thompson Sampling}
Statistical relational models have been proposed to tackle
various problems of knowledge bases. For example, it can be used 
for question understanding and answering problems \cite{Dong2015},
or it can be integrated into a search engine
to improve the users' search experiment \cite{dong2014knowledge}.

However, most of previous work does not consider a systemic way of constructing
a knowledge graph from scratch. Distant supervision algorithms
\cite{Mintz2009} suggest a way to fill a missing part of knowledge graph
through the extensive NLP processing, however, this method inherently
requires a set of initial observations used as a distant supervision.

A goal of knowledge base construction is to acquire a maximum number
of valid triples within a limited budget.
The goal corresponds to a general objective of the multi-armed bandit (MAP)
problem where we want to minimise the cumulative regret or maximise
the cumulative reward over time. Here, we tackle the problem of knowledge 
base construction through Thompson sampling which provides a principled
way to find an optimal trade off between exploration and exploitation.


Thompson sampling 
$\prod_n p(x_i|\theta)p(\theta)$

With a slight abuse of notations, we now let $\mathcal{X}^{t}$ be a set of observed triples up to time $t$.

$H$ be the number of particles, and $\Theta= \{E, \mathcal{R}\}$ be a set of latent features.
%Algorithm \ref{alg:smc} describes basic particle Thompson sampling for the tensor factorisation.
Algorithm \ref{alg:rbsmc} describes Rao-Blackwellized particle Thompson sampling where relation matrix $R_k$ is marginalized out.

Under the mild assumption where $p(\Theta | \mathcal{X}^{t-1}) \approx p(\Theta | \mathcal{X}^{t})$, the weight of each particle at time $t$ can be computed as follows \cite{del2006sequential,chopin2002sequential}:
\begin{align}
w_{h}^{t} = \frac{p(\mathcal{X}^{t} | \Theta)}{p(\mathcal{X}^{t-1} | \Theta)} = p(x^{t} | \Theta, \mathcal{X}^{t-1})
\end{align}


%\subsection{(?)Particle Thompson sampling with SGLD kernel}
%Above two algorithms are not well suitable for large scale dataset because the sample requires quantities estimated over all possible triples.
%
%Is it possible to use the stochastic gradient Langevin dynamics (SGLD) \cite{welling2011bayesian} kernel $K(E' | E)$ to sample $E'$ given $E$ with or without auxiliary variable $R_k$?
%\begin{align}
%e_i' \leftarrow e_i + \frac{\epsilon_t}{2}\Bigg\{\nabla \log p(\mathcal{X}|e_i) + \nabla \log p(e_i|\sigma_e)\Bigg\} + \nu_t
%\end{align}
%where, $\nu_t \sim \mathcal{N}(0, \epsilon_t I)$.

\begin{algorithm}[t!]
   \caption{Particle Thompson Sampling for Tensor Factorisation}
   \label{alg:smc}
\begin{algorithmic}
   \STATE {\bfseries Input:} $\mathcal{X}, \sigma_x, \sigma_e, \sigma_r$.
   \FOR{$t=1,2, \dots$}
   \STATE \textit{Thompson Sampling}:
   \STATE $h_t \sim $ Cat$(\mathbf{w}^{t})$
   \STATE $(i,k,j) \leftarrow \arg\max p(x_{ikj}| E^{h_t}, \mathcal{R}^{h_t})$
   \STATE Observe $x_{ikj}$ and update $\mathcal{X}$

   \STATE \textit{Particle Filtering}:
   \STATE $\forall h, w_h^{t+1} \propto p(x_{ikj} | E^{h}, \mathcal{R}^{h})$   \hfill $\triangleright$ Reweighting
   \IF{ESS$(\mathbf{w}^{t+1}) \leq N$}
   \STATE resample particles
   \STATE $w_h^{t+1} \leftarrow 1/H$
   \ENDIF

   \FOR{$h=1$ {\bfseries to} $H$}
   \STATE $\forall k, R_k^{h} \sim p(R_k | \mathcal{X}, E^{h})$   \hfill $\triangleright$ see Eq. (\ref{eqn:sample_r})
   \STATE $\forall i, e^{h}_i \sim p(e_i | \mathcal{X}, E^{h}_{-i}, \mathcal{R}^{h})$ \hfill $\triangleright$ see Eq. (\ref{eqn:sample_e})
   \ENDFOR

   \ENDFOR
\end{algorithmic}
\end{algorithm}

%\begin{algorithm}[t!]
%   \caption{Rao-Blackwallized Particle Thompson Sampling for Tensor Factorisation}
%   \label{alg:rbsmc}
%\begin{algorithmic}
%   \STATE {\bfseries Input:} $\sigma_x, \sigma_e, \sigma_r$.
%   \FOR{$t=1,2, \dots$}
%   \STATE \textit{Thompson Sampling}:
%   \STATE $h_t \sim $ Cat$(\mathbf{w}^{t})$
%   \STATE $(i,k,j) \leftarrow \arg\max p(x_{ikj}| E^{h_t})$    \hfill $\triangleright$ see Eq. (\ref{eqn:marginal_predict})
%   \STATE Observe $x_{ikj}$ and update $\mathcal{X}^{t}$
%
%   \STATE \textit{Particle Filtering}:
%   \STATE $\forall h, w_h^{t+1} \propto p(x_{ikj} | E^{h})$   \hfill $\triangleright$ Reweighting, Eq. (\ref{eqn:marginal_predict})
%   \IF{ESS$(\mathbf{w}^{t+1}) \leq N$}
%   \STATE resample particles
%   \STATE $w_h^{t+1} \leftarrow 1/H$
%   \ENDIF
%
%   \FOR{$h=1$ {\bfseries to} $H$}
%   \STATE $\forall k, R_k^{h} \sim p(R_k | \mathcal{X}^{t}, E^{h})$   \hfill $\triangleright$ Auxiliary sampling, see Eq. (\ref{eqn:sample_r})
%   \STATE $\forall i, e^{h}_i \sim p(e_i | \mathcal{X}^{t}, E^{h}_{-i}, \mathcal{R}^{h})$ \hfill $\triangleright$ see Eq. (\ref{eqn:sample_e})
%   \ENDFOR
%
%   \ENDFOR
%\end{algorithmic}
%\end{algorithm}
%
