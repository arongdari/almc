%!TEX root = ./icml2016.tex
\section{Bayesian RESCAL}
A relational knowledge base consists of a set triples in the form of $(i, k, j)$ where $i$, $j$ are entities, and $k$ is a relation. A triple can be distinguished in a valid triple and invalid triple based on a semantic meaning of a triple. An example of valid triple in Freebase is (Barack Obama, president of, U.S.), and an example of invalid triple is (Barack Obama, president of, U.K.).
Typically, a knowledge base only contains a set of valid triples, but in this research, we assume that the knowledge base contains a set of invalid triples as well. The knowledge base can also be represented in a three-way tensor 
$\mathcal{X} \in \{0, 1\}^{N \times K \times N}$, where $K$ is a number of relations, $N$ is a number of entities, and $x_{ikj}$ is an indicator variable representing a validity of the triple. 

The goal of the statistical relational learning is to factorise the tensor into a set of latent vector representations. The bilinear model (RESCAL) is a common vector space model for knowledge base completion \cite{nickel2011three}. RESCAL aims to factorise each relational slice $X_{:k:}$ into a set of $D$-rank latent features as follows:
\begin{align}
\mathcal{X}_{:k:} \approx E R_k E^\top, \qquad \text{for } k = 1, \dots, K
\end{align}
Here, $E$ is a $N\times D$ matrix that contains the latent features of the entities and $R_k$ is a $D \times D$ matrix that models the interaction of the latent features between entities in relation $k$.

We generalise RESCAL in a probabilistic framework by placing priors over the latent features. For each entity $i$, the latent feature of an entity $e_i \in \mathbb{R}^{D}$ is drawn from an isotropic multivariate-normal distribution.
\begin{align}
\label{eqn:entity_gen}
e_i \sim {N}(\mathbf{0}, \sigma_e^2{I}_D)
\end{align}
For each relation $k$, we draw matrix $R_k \in \mathbb{R}^{D\times D}$ from zero-mean isotropic matrix normal distribution.
\begin{align}
\label{eqn:relation_gen}
R_k \sim \mathcal{MN}_{D \times D}(\mathbf{0}, \sigma_r{I}_D, \sigma_r{I}_D) \\
\text{vec}(R_k) = r_k \sim N(\mathbf{0}, \sigma_r^2 I_{D^2}) \notag
\end{align}

\textbf{Binary output varialbe}:
For binary valued triples we use a logistic regression model:
\begin{align}
p(x_{ikj}=1) = \sigma(e_i^{\top} R_k e_j, \sigma_x^2)
\end{align}

\textbf{Gaussian output variable}:
For each triple $(i,k,j)$, we draw $x_{ikj}$
\begin{align}
\label{eqn:triple_gen}
x_{ikj} |e_i, e_j, R_k &\sim \mathcal{N}(e_i^{\top} R_k e_j, \sigma_x^2)\\
& = \mathcal{N}(r_k^{\top} e_i \otimes e_j, \sigma_x^2) \notag
\end{align}


The conditional distribution of $e_i$ given $\mathcal{R}$ and other entities $E_{-i}$
\begin{align} \label{eqn:sample_e}
p(e_i |E_{-i}, \mathcal{R}, \mathcal{X}^{t}, \sigma_e, \sigma_x) &= \mathcal{N}(e_i | \mu_i, \Lambda_i^{-1}),
\end{align}
where
\begin{align*}
\mu_i &= \frac{1}{\sigma_x^2}\Lambda_i^{-1}\xi_i \\
\Lambda_i &= \frac{1}{\sigma_x^2} \sum_{jk : x_{ikj} \in \mathcal{X}^{t}} (R_k e_j)(R_k e_j)^\top \\
&\quad+ \frac{1}{\sigma_x^2} \sum_{jk : x_{jki} \in \mathcal{X}^{t}} (R_k^\top e_j)(R_k^\top e_j)^\top+ \frac{1}{\sigma_e^2} {I}_D \\
\xi_i &= \sum_{jk : x_{ikj} \in \mathcal{X}^{t}}  x_{ikj} R_{k} e_{j} + \sum_{jk : x_{jki} \in \mathcal{X}^{t}} x_{jki} R_{k}^\top e_{j}.
\end{align*}
The conditional distribution of $R_k$ given $E$
\begin{align}
\label{eqn:sample_r}
p(R_k|E, \mathcal{X}, \sigma_r, \sigma_x)  &= \mathcal{N}(\text{vec}(R_k) | \mu_k, \Lambda_k^{-1}),
\end{align}
where
\begin{align*}
\mu_k &= \frac{1}{\sigma_x^2}\Lambda_k^{-1}\xi_k \\
\Lambda_k &= \frac{1}{\sigma_x^2} \sum_{ij:x_{ikj} \in \mathcal{X}^{t}} (e_i \otimes e_j)(e_i \otimes e_j)^\top + \frac{1}{\sigma_r^2} {I}_{D^2} \\
\xi_k &= \sum_{ij:x_{ikj} \in \mathcal{X}^{t}} x_{ikj} (e_{i} \otimes e_{j}).
\end{align*}

The posterior marginal predictive distribution of $x_{ikj}$ given $\mathcal{X}$ and $E$ is
\begin{align}
\label{eqn:marginal_predict}
&p(x_{ikj}| E, \mathcal{X}^{t}, \sigma_x, \sigma_r) \\
&= \mathcal{N}(x_{ikj}| \mu_k ^\top (e_i \otimes e_j), \frac{1}{\sigma_x^2} +  (e_i \otimes e_j)^\top \Lambda_k (e_i \otimes e_j)). \notag
\end{align}
