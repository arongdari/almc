% !TEX TS-program = pdflatexmk
\documentclass{article} % For LaTeX2e
\usepackage{nips15submit_e,times}
\usepackage{hyperref}
\usepackage{url}
%\documentstyle[nips14submit_09,times,art10]{article} % For LaTeX 2.09

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\newcommand\myeq{\stackrel{\mathclap{\tiny\mbox{d}}}{=}}


\title{Thompson Sampling for Exchangeable Array with Random Function Prior}


\author{
Dongwoo Kim
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle

\begin{abstract}
This is abstract.
\end{abstract}

\section{Exchangeable Array}

\begin{definition}[Exchangeable 2-array] A random 2-array ($X_{ij}$) is called separately exchangeable if
\begin{align}
(X_{ij}) \myeq (X_{\pi(i)\pi'(j)})
\end{align}
for every pair of permutations $\pi$, $\pi'$ of $\mathbb{N}$.
\end{definition}

\begin{theorem}[Aldous]\label{thm:exarray} A random array ($X_{ij}$) is separately exchangeable if and only if it can be represented as follows: There is a random function $F:[0,1]^3 \rightarrow \mathcal{X}$ such that
\begin{align}
(X_{ij}) \myeq (F(U_i, V_j, U_{ij}))
\end{align}
where $(U_i)_{i\in\mathbb{N}}$, $(V_j)_{j\in\mathbb{N}}$, $(U_{ij})_{i,j\in\mathbb{N}}$ are two sequences and an array of i.i.d. Uniform[0,1] random variables, which are independent of F.
\end{theorem}

\section{Model}
Based on Theorem \ref{thm:exarray}, we define a Bayesian model for exchangeable arrays.
\begin{align}
(X_{ij}) \myeq (F(U_i, U_j, U_{ij})) = H(U_{ij}, \Theta(U_i, V_j))
\end{align}
$\Theta:[0,1]^2 \rightarrow W$ and $H:[0,1] \times W \rightarrow \mathcal{X}$.
For real valued output varialbe $X_{ij}$, we define $H$ an inverse CDF of gaussian distribution with mean parameter $\Theta(U_i, V_j)$, and variance $\sigma^2$.
\begin{align}
\Theta \sim \mathcal{GP}(0, \kappa)\\
U_1, U_2, ... \sim \text{Uniform}[0,1]\\
V_1, V_2, ... \sim \text{Uniform}[0,1]\\
W_{ij} = \Theta(U_i, V_j) \\
X_{ij} | W_{ij} \sim \mathcal{N}(X_{ij}| W_{ij}, \sigma^2_\mathcal{X})
\end{align}


\section{Posterior Inference}
Sampling $(U_i)$ and $(V_j)$ can be done with slice sampling. Hyper parameter of Gaussian process is also optimised given $(U_i)$ and $(V_j)$.

\section{Thompson Sampling}
Given $U$ and $V$, the posterior predictive distribution of GP can be analytically computed, of which mean function is a smooth function over the product space.

Posterior predictive distribution of $X$ on unobserved pair $U_*, V_*$ is
\begin{align}
p(X_* | {U}_*, {V}_*, \mathbf{x}, \mathbf{U}, \mathbf{V}) = \mathcal{N}(\mu_*, \sigma_*^2)\\
\mu_* = \mathbf{K}_{*N}(\mathbf{K}_N + \sigma^2 I)^{-1} \mathbf{x} \label{eqn:pmean}\\
\sigma_*^2 = K_{**} - \mathbf{K}_{*N}(\mathbf{K}_N + \sigma^2 I)^{-1} \mathbf{K}_{N*} + \sigma^2,
\end{align}
where we let $\mathbf{x}$ be the sequence of observations so far, and $\mathbf{K}$ be the corresponding kernel matrix.

To apply Thompson sampling algorithm to this model, at each time $t$, we have to sample unobserved entry $X_{ij}$ of pair $U_i$ and $V_j$ from this posterior. Again, the number of required posterior sampling increases quadratically as the number of $U$ and $V$ increases. Instead of sampling  individual pairs, is there a way to sample a posterior function in an analytic form, so that we do some maximisation on this function? For example, if we place a prior over the hyper-parameters of the kernel function and sample the hyper-parameters \cite{neal1997monte}, and finding a maximum point ($U_*$, $V_*$) of the posterior mean function given these hyper-parameters, then can we say that this pair $U_*$ and $V_*$ is a new sample by Thompson sampling? (even this posterior function does not take into account the variance of an individual observation) (or the most close pair $U_*'$ and $V_*'$ from $U_*$ and $V_*$ if corresponding $U_*$ and $V_*$ does not exist) Does this help to reduce the computation complexity of the posterior sampling? Is it better than the UCB-based algorithm? \cite{krause2011contextual}

\bibliographystyle{plain}
\bibliography{ref}

\end{document}
