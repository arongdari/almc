% !TEX TS-program = pdflatexmk
\documentclass{article}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{amsthm}


\newtheorem{theorem}{Theorem} %This is the example presented in the introduction but it has the additional parameter [section] that restarts the theorem counter at every new section.
\newtheorem{corollary}{Corollary}[theorem] %A environment called corollary is created, the counter of this new environment will be reset every time a new theorem environment is used.
\newtheorem{lemma}[theorem]{Lemma} %In this case, the even though a new environment called lemma is created, it will use the same counter as the theorem environment.

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{example}{Example}[definition]
\newtheorem{remark}{Remark}

\title{Exchangeable Array and Random Graph}
\date{\today}
\author{Dongwoo Kim\\ANU}

\begin{document}

\maketitle

\section{Exchangeable array for graph}
\begin{definition}[Jointly exchangeable array] A random 2-array $(X_{ij})_{i,j\in \mathbb{N}}$
is jointly exchangeable if
\begin{align}
(X_{ij}) \stackrel{d}{=} (X_{\pi(i)\pi(j)}) \quad \text{for } i,j \in \mathbb{N}^2
\end{align}
for any permutation $\pi$ of $\mathbb{N}$.
\end{definition}

\begin{theorem}[\label{aldous_hoover}Aldous, Hoover Theorem \cite{aldous1981representations,hoover1979relations}] A random 2-array $(X_{ij})_{i,j\in \mathbb{N}}$
is jointly exchangeable if and only if there exists a random measurable function $f:[0,1]^3 \rightarrow \mathbf{X}$ such that
\begin{align}
(X_{ij}) \stackrel{d}{=} (f(U_i, U_j, U_{ij})),
\end{align}
where $(U_{i})_{i \in \mathbb{N}}$ and $(U_{ij})_{ij>i\in\mathbb{N}}$ with $U_{ij} = U_{ij}$ are a sequence and matrix of i.i.d. Uniform[0,1] random variables.
\end{theorem}
The function $f$ is a symmetric in its first two argument.

For the undirected graph case $\mathcal{X} = \{0,1\}$, the theorem can be simplified further through a random function called \textit{graphon} $W:[0,1]^2 \rightarrow [0,1]$, symmetric in its arguments, where
\[ f(U_i, U_j, U_{ij}) = 
  \begin{cases}
    1       & \quad U_{ij} < W(U_i, U_j)\\
    0  & \quad \mathrm{otherwise}\\
  \end{cases}
\]

\begin{example}[Random function prior on function $f$ \cite{Lloyd2013}] Lloyd et al. use a Gaussian process prior to define function $f$ for an undirected graph. They define $W(U_i, U_j) = \phi(\Theta(U_i,U_j))$ where $\phi$ is a logstic function, and $\Theta(\cdot, \cdot)$ is a continuous function with a Gaussian process prior. Thus, the probability of edge between node $i$ and $j$ is equal to Bernoulli$(\phi(\Theta(U_i,U_j)))$.
\end{example}

\begin{definition}[Sparse Graph]
Let the number of nodes in a graph be $n$. The graph is sparse if the number of edges are $o(n^2)$ or dense if the number of edges are $\Theta(n^2)$.
\end{definition}

\begin{remark}[Graphon is trivially dense]
Every graph represented by graphon $W$ are either empty or dense. The asymptotic proportion of edges is $p = \frac{1}{2}\int W(x, y) dxdy$ and the graph is hence either empty $(p=0)$ or dense (since $O(pn^2) = O(n^2)$).
\end{remark}

In \cite{Lloyd2013}, the authors place a Gaussian process prior over graphon $W:[0,1]^2 \rightarrow \mathbb{R}$ and transform the output through the logistic function to model the edge probability between nodes.

For the undirected graph case where $X_{ij} = X_{ji}$, one can sample upper triangle of the adjacency matrix, and use the same result for the lower triangle. However, for the directed graph case, by the theorem, both $X_{ij}$ and $X_{ji}$ rely on single parameter $U_{ij}$ which means one should jointly sample ($X_{ij}$, $X_{ji}$) together from three parameters $U_{i}, U_{j}, U_{ij}$. Thus, $X_{ij}$ and $X_{ji}$ are not conditionally independent. Also, asymmetric graphon $W$ might be employed for directed random graph. However, \cite{Cai2015} show that assymetric graphon is inappropriate to impose certain structures on a graph such as the partial ordering and propose a class of priors for directed graphs.

\section{Exchangeable array for matrix factorisation}
Unlike the graph model, jointly exchangeability for a general matrix where rows and columns represent different entities (i.e. users and items in recommendation system) is

\begin{definition}[Separately exchangeable array \cite{Orbanz2015}]A random 2-array $(X_{ij})_{i,j\in \mathbb{N}}$ is separately exchangeable if
\begin{align}
(X_{ij}) \stackrel{d}{=} (X_{\pi(i)\sigma(j)}) \quad \text{for } i,j \in \mathbb{N}^2
\end{align}
for any permutation $\pi$ and $\sigma$ of $\mathbb{N}$.
\end{definition}

\begin{corollary}[\label{sea}Separately exchangeable array] A random 2-array $(X_{ij})$ is separately exchangeable if and only if there exists a random measurable function $f:[0,1]^3 \rightarrow \mathbb{X}$ such that
\begin{align}
(X_{ij})  \stackrel{d}{=} (f(U_i, U_j, U_{ij})),
\end{align}
where $(U_i)_{i\in \mathbb{N}}$, $(U_j)_{j\in \mathbb{N}}$, and $(U_{ij})_{ij\in \mathbb{N}^2}$ are i.i.d. uniform[0,1] random variables.
\end{corollary}
In the separately exchangeable array case, function $f$ is not a symmetric in its first two arguments.

\begin{example}[Probabilistic matrix factorisation (PMF) \cite{Salakhutdinov2008}] 
PMF is one instantiation of Corollary \ref{sea}. Let the generative process of PMF be
\begin{align}
U_i &\sim \mathcal{MN}_d(0, \Sigma_U)\\
V_j &\sim \mathcal{MN}_d(0, \Sigma_V)\\
X_{ij} &\sim \mathcal{N}(U_i^\top V_j, \sigma_x)
\end{align}
where $\mathcal{MN}_d$ is a $d$-dimensional zero-mean multivariate normal distribution with covariance $\Sigma$. This corresponds to random measurable function
$f(U_i, U_j, U_{ij}) = \Phi_1(U_{ij}; \Phi_d(U_i;0, \Sigma_{U})^\top \Phi_d(U_j;0, \Sigma_{U}), \sigma^2_x)$, where $\Phi_d(\cdot;\mu, \sigma^2)$ is an inverse-CDF of $d$-dimensional multivariate function with mean $\mu$ and variance $\sigma^2$.
\end{example}


\section{Sparse exchangeable array}
\begin{theorem}[Kallenberg's exchangeable theorem \cite{Kallenberg1990}] Representation theorems for jointly exchangeable random measures on $\mathbb{R}^2$
\end{theorem}

Matrix factorisation for the sparse bipartite graph has been partially discussed in \cite{Caron2012}.

\bibliographystyle{apalike}
\bibliography{ref}

\end{document}
