% !TEX TS-program = pdflatexmk
\documentclass{article}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage[a4paper, total={6in, 8in}]{geometry}
\usepackage{amsthm}
\usepackage{natbib}


\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

\title{Sparse Graph Prior for Knowledge Graph}
\date{\today}
\author{Dongwoo Kim\\ANU}

\begin{document}

\maketitle

\section{Completely Random Measure}
A completely random measure (CRM) $\mu$ on $\mathbb{R}_+$ is a random measure such that for any countable number of disjoint measurable sets $A_1, A_2, ...$ of $\mathbb{R}_+$, the random variable $\mu(A_1), \mu(A_2), ...$ are independent and $\mu(\cup_i A_i) = \sum_i \mu(A_i)$. If one assumes that the distribution of $\mu([t,s])$ only depends on $t-s$ then the CRM takes the form of $\mu = \sum_{i=1}^{\infty}w_i\delta_{\theta_i}$ where $(w_i, \theta_i)$ are the points of a Poisson point process on $\mathbb{R}_+^2$ with L\'{e}vy intensity measure $\nu(dw, d\theta) = \rho(dw)\lambda(d\theta)$. The Laplace transform of $\mu(A)$ on any measurable set $A$ has a following representation: $\mathbb{E}[e^{-t\mu(A)}] = \exp(-\int_{\mathbb{R}_+ \times A}(1-e^{-tw})\rho(dw)\lambda(d\theta))$ for any $t>0$ and $\rho$ such that $\int_{\mathbb{R}_+}(1-e^{-w})\rho(dw) < \infty$.

\section{Caron and Fox Model}

\cite{Caron2015} propose a simple point process on $\mathbb{R}^2$ as a product measure of a complete random measure. They propose a hierarchical model for undirected graphs
\begin{align}
\mu &= \sum_{i=1}^{\infty} w_i \delta_{\theta_i} & &\mu \sim \text{CRM}(\rho, \lambda)\\
D &= \sum_{i,j} n_{ij} \delta_{(\theta_i, \theta_j)} & &D|\mu \sim \text{PP}(\mu \times \mu)\\
Z &=\sum_{i,j} \min(n_{ij} + n_{ji}, 1)\delta_{(\theta_i, \theta_j)}, \label{eqn:cnf}&&
\end{align}
with intensity measure $\nu$ factorising as $\nu(dw, d\theta) = \rho(dw) \lambda(d\theta)$ for a jump part of the measure $\rho$ and Lebesgue measure $\lambda$. $D$ is simply generated from a Poisson process with a product measure as an intensity and can be interpreted as a directed multi-graph.
Given $\mu$, we can directly specify the undirected graph $Z$ as
\[ Pr(z_{ij}=1|w) = 
  \begin{cases}
    1 - \exp(-2w_iw_j)       & \quad i \neq j\\
    1 - \exp(-w_i^2) & \quad i = j.\\
  \end{cases}
\]

They show that the resulting graph is sparse, i.e. \# of edges = $o$(\# of nodes$^2$)\footnote{only counts the nodes which has at least one edge}, if the intensity measure\footnote{This is the L\'{e}vy intensity of the generalised gamma process} is
\begin{align}
\rho(dw) = \frac{1}{\Gamma(1-\sigma)}w^{-1-\sigma}e^{-\tau w}dw,
\end{align}
where the two parameters range
\begin{align}
(\sigma, \tau) \in (0,1) \times [0, +\infty)
\end{align}
and dense if the intensity measure is finite activity, i.e. $\int_{0}^{\infty} \rho(w)dw < \infty$.

The general construction of the sparse graph in Equation \ref{eqn:cnf} results an infinite number of edges due to $\mu(\mathbb{R}_+) = \infty$. A restriction of Lebesgue measure $\lambda$ on $[0, \alpha]$ is used to obtain a finite graph ($\lambda_\alpha = \lambda\delta_{[0, \alpha]}$). Therefore, restricted graph $Z_\alpha$ is defined on the box $[0,\alpha]^2$. We also denote the total mass on $[0, \alpha]^2$ by $Z_\alpha^* = Z_\alpha([0, \alpha]^2)$, and similarly for $D_\alpha^*$ and $\mu_\alpha^*$.

\section{Sparse Prior for Knowledge Graph}
A knowledge base consists of a set of triples (entity, entity, relation) such as (BarackObama, bornIn, Hawaii). The set of triples can be represented as a binary-valued three-way tensor where three dimensions represent entity, entity, and relation, respectively. Here, we directly extend the Caron and Fox's model for the three-way tensor based on two independent completely random measures.
\begin{align}
\mu &= \sum_{i=1}^{\infty} w_i \delta_{\theta_i} & &\mu \sim \text{CRM}(\rho, \lambda)\\
\mu' &= \sum_{k=1}^{\infty} w_k \delta_{\theta_k'} & &\mu' \sim \text{CRM}(\rho', \lambda)\\
D &= \sum_{i,j,k} n_{ijk} \delta_{(\theta_i, \theta_j, \theta_k')}& &D \sim \text{PP}(\mu \times \mu \times \mu') && \\
Z &=\sum_{i,j,k} \min(n_{ijk}, 1)\delta_{(\theta_i, \theta_j, \theta_k')}, &&
\end{align}
where $Z$ is asymmetric in $i$ and $j$ since the knowledge graph is a directed multi-graph. As done in the original model, we can also specify $Z$ as
\[ Pr(z_{ijk}=1|w, w') = 
  \begin{cases}
    1 - \exp(-w_iw_jw_k')       & \quad i \neq j\\
    1 - \exp(-w_i^2w_k') & \quad i = j.\\
  \end{cases}
\]
If we consider $\theta_i$, $\theta_j$, and $\theta_k'$ as nodes in the graph, the above construction will generate a hypergraph where each edge connects three nodes. In the notion of knowledge graphs, it is more intuitive to consider a relation as a type of edge between two entities. In this case, we define two random measures on $\mathbb{R}_+^2$:
\begin{align}
\bar{D} &= \sum_{i,j}\sum_{k}z_{ijk}\delta_{\theta_i,\theta_j}\\
\bar{Z} &= \sum_{i,j}\min(\bar{D}(\{\theta_i, \theta_j\}), 1) \delta_{(\theta_i,\theta_j)},
\end{align}
where $\bar{D}$ is a multigraph, and $\bar{Z}$ is a binary graph of a knowledge base.
\[ Pr(\bar{z}_{ij}=1|w, w') = 
  \begin{cases}
    1 - \exp(-w_iw_j\sum_{k}w_k')       & \quad i \neq j\\
    1 - \exp(-w_i^2\sum_{k}w_k') & \quad i = j.\\
  \end{cases}
\]
To obtain a finite hypergraph (the number of edges is finite), we consider restrictions ${D}_{\alpha\beta}$ and ${Z}_{\alpha\beta}$ to the box $[0,\alpha]^2\times[0,\beta]$. We denote by $Z_{\alpha\beta}^* = Z_{\alpha\beta}([0,\alpha]^2\times[0,\beta])$ the total mass on the restricted area, and similar for $D_{\alpha\beta}^*$ and $\mu_{\alpha}^*$.

\subsection{Generative Process through Urn approach}
Given restriction $\alpha$ and $\beta$, the generative process of $D_{\alpha\beta}$ can be specified as follows:
\begin{enumerate}
\item $\mu_\alpha \sim \text{CRM}(\rho, \lambda_\alpha)$
\item $\mu_\beta' \sim \text{CRM}(\rho', \lambda_\beta)$
\item $D_{\alpha\beta}^* | \mu_\alpha, \mu_\beta' \sim \text{Poisson}(\mu_\alpha^{*2}\mu_\beta^{'*})$
\item For $d=1,...,D_{\alpha\beta}^*$:
\begin{enumerate}
\item $\theta_{di} \sim \frac{\mu_\alpha}{\mu_\alpha^*}$
\item $\theta_{dj} \sim \frac{\mu_\alpha}{\mu_\alpha^*}$
\item $\theta_{dk}' \sim \frac{\mu_\beta}{\mu_\beta^{'*}}$
\end{enumerate}
\item $D_{\alpha\beta} = \sum_{d=1}^{D_{\alpha\beta}^*} \delta_{(\theta_{di}, \theta_{dj}, \theta_{dk})}$,
\end{enumerate}
where we have used that the total mass of $D_{\alpha\beta}^*$ follows the Poisson distribution. Each node $\theta_i$ is drawn from the normalised CRM (NRM), $\frac{\mu_\alpha}{\mu_\alpha^*}$, which is discrete with probability 1. However, it is not possible to sample $\mu_\alpha$ and $\mu'_\beta$ since these measures have infinite number of atoms. Instead we can simulate finite-dimensional generative process through the urn formulation. Let $\theta_1, ..., \theta_n$ drawn from the normalised CRM $\frac{\mu_\alpha}{\mu_\alpha^*}$. Since NRM is discrete, variables $\theta_1, ..., \theta_n$ takes $l \leq n$ distinct values $\phi_l$, and $m_l$ is the number of variables corresponding to $\phi_l$.
Given total mass $\mu_\alpha^*$ and $\theta_1, ..., \theta_n$, the conditional distribution of $\theta_{n+1}$ can be modelled in terms of exchangeable partition probability function (EPPF):
\begin{align}
\label{eqn:eppf}
\theta_{n+1} | \mu_\alpha^*, \theta_1,...,\theta_n \sim \frac{\Pi_{n+1}^{l+1}(m_1, ..., m_l, 1 | \mu_\alpha^*)}{\Pi_{n}^{l}(m_1, ..., m_l | \mu_\alpha^*)} \frac{1}{\alpha} \lambda_\alpha
+ \sum_{i=1}^{l}\frac{\Pi_{n+1}^{l}(m_1, ..., m_{i}+1, ..., m_l | \mu_\alpha^*)}{\Pi_{n}^{l}(m_1, ..., m_l| \mu_\alpha^*)} \delta_{\phi_l}
\end{align}
where
\begin{align}
\Pi_{n}^l(m_1, ..., m_l|\mu_\alpha^*) = \frac{\sigma^l \mu_\alpha^{*-n}}{\Gamma(n-l\sigma)g_{\sigma}(\mu_\alpha^*)} \int_{0}^{\mu_\alpha^*}s^{n-l\sigma-1}g_{\sigma}(\mu_\alpha^*-s)ds \bigg(\prod_{i=1}^{l} \frac{\Gamma(m_i-\sigma)}{\Gamma(1-\sigma)} \bigg),
\end{align}
and $g_\sigma$ is the pdf of the positive stable distribution.
Finally, the total mass of $\mu_\alpha^*$ and $\mu_\beta^{'*}$ follows an exponentially tilted stable distribution where the exact sampler exists \citep{devroye2009random,hofert2011sampling}. 

Using this urn representation, we can rewrite the generative process as
\begin{enumerate}
\item $\mu_\alpha^* \sim P_{\mu_\alpha^*}$
\item $\mu_\beta^{'*} \sim P_{\mu_\beta^{'*}}$
\item $D_{\alpha\beta}^* | \mu_\alpha, \mu_\beta' \sim \text{Poisson}(\mu_\alpha^{*2}\mu_\beta^{'*})$
\item For $d=1,...,D_{\alpha\beta}^*$:
\begin{enumerate}
\item Sample $\theta_{di}$, $\theta_{dj}$, and $\theta_{dk}'$ with Urn process in Eqn \ref{eqn:eppf}
\end{enumerate}
\item $D_{\alpha\beta} = \sum_{d=1}^{D_{\alpha\beta}^*} \delta_{(\theta_{di}, \theta_{dj}, \theta_{dk})}$,
\end{enumerate}

\subsection{Sparsity}

\begin{theorem} \label{thm:edge} Consider the point process $\bar{Z}$ with infinite-activity intensity measures $\rho(dw)$ and $\rho'(dw')$. Given $\mu'$ from $\rho'(dw')$, the number of edges in $\bar{Z}_{\alpha}$ grows quadratically as $\alpha \rightarrow \infty$ almost surely.
\end{theorem}
\begin{proof}
$\sum_{k=1}^{\infty} w_k' < \infty$ a.s. When $\mu'$ is given and the sum of $w_k'$ is finite a.s., we can use the same proof technique used in \cite{Caron2015}.
\end{proof}
What if $\mu'$ is not given? Let $(X_i)$ and $(Y_k)$ be i.i.d. real-valued random variable from $p$ and $q$, respectively, and let $h(x_1, x_2, y_1)$ be a measurable function symmetric in the first two arugments. 
\begin{align}
\frac{2 \sum_{i<j}\sum_{k} h(X_i, X_j, Y_k)}{n_x(n_x -1) n_y} \xrightarrow[]{?} \mathbb{E}[h(X_i, X_j, Y_k)]\quad a.s.\quad as \quad n\rightarrow \infty
\end{align}
If this strong law of the large numbers for two samples is correct, we may proof Theorem 3.1 in more general case ($\mu'$ is not given).

\begin{theorem} Consider the point process $\bar{Z}$ with infinite-activity intensity measures $\rho(dw)$ and $\rho'(dw')$. Let $N_\alpha$ be a number of nodes having at least one connection. Given $\mu'$ from $\rho'(dw')$, the number of nodes $N_\alpha$ in $\bar{Z}_{\alpha}$ grows superlinearly as $\alpha \rightarrow \infty$ almost surely.
\end{theorem}
\begin{proof}
As \ref{thm:edge}.
\end{proof}

\subsection{Posterior inference}
We first characterise the posterior of $\mu_\alpha$ given $\mu'_\beta$ and $D_{\alpha\beta}$. The conditional Laplace functional of $\mu_\alpha$ given $D_{\alpha\beta}$ is $\mathbb{E}[e^{-\mu_\alpha(f)}|\mu'_\beta, D_{\alpha\beta}]$, for any non-negative measurable function $f$. We have $\mu_\alpha(f) = \Pi(\tilde{f})$ where $\Pi = \sum_{i=1}^{\infty} \delta_{w_i, \theta_i}$ is a Poisson random measure on $(0, \infty) \times [0, \alpha]$ with mean measure $\rho \times \lambda$ and $\tilde{f}(w, \theta) = wf(\theta)$. Let $m_i = \sum_{j=1}^{N_\alpha}\sum_{k=1}^{N_\beta} n_{ijk} + n_{jik}$, $m'_k = \sum_{i=1}^{N_\alpha} \sum_{j=1}^{N_\alpha} n_{ijk}$, and $m^* = \sum_{i=1}^{N_\alpha} m_i$.

\begin{align}
\mathbb{E}_{\mu_\alpha}[e^{-\mu_\alpha(f)}|D_{\alpha\beta}, \mu'_\beta] = \mathbb{E}_{\Pi}[e^{-\Pi(\tilde{f})}|D_{\alpha\beta}, \mu'_\beta] = \frac{\mathbb{E}_{\Pi}[e^{-\int \tilde{f}(w, \theta)\Pi(dw, d\theta)} P(D_{\alpha\beta}|\Pi, \mu'_\beta)]}{\mathbb{E}_{\Pi}[P(D_{\alpha\beta}|\Pi, \mu'_\beta)]}
\end{align}
where
\begin{align}
P(D_{\alpha\beta}|\Pi, \mu'_\beta) & = P(D_{\alpha\beta}|\mu_\alpha, \mu'_\beta)\\
& = \text{Poisson}(\mu_\alpha^{*2}\mu_\beta^{'*}) \times \prod_{i=1}^{N_\alpha} 
P(m_i|\mu_\alpha) \times \prod_{k=1}^{N_\beta}P(m'_{k}| \mu'_\beta) \\
& = \frac{ (\mu_\alpha^{*2}\mu_\beta^{'*})^{m^*} e^{-\mu_\alpha^{*2}\mu_\beta^{'*}} }{m^*!}
%\frac{m^*!}{\prod_{i=1}^{N_\alpha}m_i!}
\prod_{i=1}^{N_\alpha} \Big( \frac{w_\alpha}{\mu_\alpha^*} \Big)^{m_i} 
\prod_{k=1}^{N_\beta} \Big( \frac{w'_\beta}{\mu_\beta^{'*}} \Big)^{m'_k}\\
\mu_\alpha^* = \sum_{i=1}^{\infty} w_i, &\qquad \mu_\beta^{'*} = \sum_{k=1}^{\infty} w'_k
\end{align}
Let's focus on the numerator:
\begin{align}
\mathbb{E}_{\Pi}[e^{-\int \tilde{f}(w, \theta)\Pi(dw, d\theta)}P(D_\alpha|\Pi, \mu'_\beta)] = 
\end{align}

\bibliographystyle{apalike}
\bibliography{ref}

\end{document}
